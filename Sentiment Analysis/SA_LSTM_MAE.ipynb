{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c046b2e",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154525ac",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43f7964f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laureneterno/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from functools import reduce\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52bbaca",
   "metadata": {},
   "source": [
    "## Save excel files from data cleaning stage into DataFrames and name the timestamp column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "361331f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nike = pd.read_excel('nike.xlsx')\n",
    "starbucks = pd.read_excel('starbucks.xlsx')\n",
    "target = pd.read_excel('target.xlsx')\n",
    "\n",
    "nike = nike.rename(columns = {'Unnamed: 0': 'timestamp'})\n",
    "starbucks = starbucks.rename(columns = {'Unnamed: 0': 'timestamp'})\n",
    "target = target.rename(columns = {'Unnamed: 0': 'timestamp'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f692e6",
   "metadata": {},
   "source": [
    "## Define getPolarity function that uses the TextBlob library to perform sentiment analysis on the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a852ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPolarity(text):\n",
    "   return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684263d4",
   "metadata": {},
   "source": [
    "## Define sentiment analysis function that cleans the string data and assigns each date a polarity score using the TextBlob library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5be963cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(df):\n",
    "    list = []\n",
    "    for x in df['comments']:\n",
    "    \n",
    "        # changes all of the characters to lowercase\n",
    "        x = str.lower(x)\n",
    "    \n",
    "        # removes all special characters\n",
    "        x = re.sub(r'[^a-zA-Z0-9\\s]+', '', x)\n",
    "    \n",
    "        # adds the modified column values to a list\n",
    "        list.append(x)\n",
    "\n",
    "        # adds the nike_list to a new dataframe\n",
    "        new_df = pd.DataFrame(list, columns =['comments'])\n",
    "\n",
    "    # adds the timestamps to the new dataframe\n",
    "    new_df = new_df.join(df['timestamp'])\n",
    "\n",
    "    # performs sentiment analysis on the comments from each day\n",
    "    new_df['polarity_score'] = new_df['comments'].apply(getPolarity)\n",
    "\n",
    "    # rearrange column order\n",
    "    new_df = new_df[['timestamp', 'polarity_score','comments']]\n",
    "\n",
    "    # set timestamp as index\n",
    "    new_df.set_index('timestamp')\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fac572",
   "metadata": {},
   "source": [
    "## Creates the new dataframe using the sentiment analysis function on each company's dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "941a2e2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nike = sentiment_analysis(nike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c155685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks = sentiment_analysis(starbucks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4ec4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = sentiment_analysis(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35449831",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e861e93",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c9883fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 20:35:22.228970: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089d6714",
   "metadata": {},
   "source": [
    "## save the stock data into csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5875ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nike_stock = pd.read_csv('nike_stock.csv')\n",
    "starbucks_stock = pd.read_csv('starbucks_stock.csv')\n",
    "target_stock = pd.read_csv('target_stock.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6101101b",
   "metadata": {},
   "source": [
    "## combine the stock data and sentiment analysis data together. we chose the close price to be our output variable for the LSTM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6ebe7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_and_clean(stock, sa):\n",
    "    \n",
    "    # drop columns not needed from initial data retreival\n",
    "    stock = stock.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis = 1)\n",
    "    \n",
    "    # change columns to datetime type\n",
    "    sa['timestamp'] = pd.to_datetime(sa['timestamp'])\n",
    "    stock['Date'] = pd.to_datetime(stock['Date'])\n",
    "    \n",
    "    # perform an inner join to combine the dataframes by the dates available for both the sentiment analysis and the stock data\n",
    "    sa = sa.merge(stock, how = 'inner', left_on='timestamp', right_on = 'Date')\n",
    "    \n",
    "    # drop the date column as it is the same as the timestamp column (since the join was performed) and drop the comments column as the sentiment analysis was already completed\n",
    "    sa = sa.drop(['Date', 'comments'], axis = 1)\n",
    "    \n",
    "    # rename the Close column to close to match the lowercase in the other column names\n",
    "    sa = sa.rename(columns = {'Close': 'close'})\n",
    "    \n",
    "    # rename the timestamp column to date\n",
    "    sa = sa.rename(columns = {'timestamp':'date'})\n",
    "    \n",
    "    # Convert 'date' to numerical feature (number of days since the start)\n",
    "    sa['days_since_start'] = (sa['date'] - sa['date'].min()).dt.days\n",
    "        \n",
    "    #return the cleaned dataframe\n",
    "    return sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "341bb20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nike = combine_and_clean(nike_stock, nike)\n",
    "starbucks = combine_and_clean(starbucks_stock, starbucks)\n",
    "target = combine_and_clean(target_stock, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462f16d8",
   "metadata": {},
   "source": [
    "## Create a long short term memory model for each of the companies that uses the date (normalized as date since the earliest date) and polarity_score from sentiment analysis as input variables and the close price as the output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e969f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(df):\n",
    "    # feature selection\n",
    "    features = df[['days_since_start', 'polarity_score', 'close']].values\n",
    "    \n",
    "    # scale the values between 0 and 1 (this is optimal for LSTM)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled = scaler.fit_transform(features)\n",
    "\n",
    "    # Define nested function to create dataset with input features and target variable\n",
    "    def create_dataset(data, length):\n",
    "        # x represents the input features\n",
    "        # y represents the output variables\n",
    "        x, y = [], []\n",
    "        for i in range(len(data) - length):\n",
    "            a = data[i:(i + length), :]\n",
    "            x.append(a)\n",
    "            y.append(data[i + length, 2])  # 'close' is the third column\n",
    "        return np.array(x), np.array(y)\n",
    "\n",
    "    # determines the sequence length for each input\n",
    "    length = 10\n",
    "\n",
    "    # create dataset\n",
    "    x, y = create_dataset(scaled, length)\n",
    "\n",
    "    # split data into training and testing\n",
    "    # test size is 20% of data\n",
    "    # random_state = 42 means that the same training and testing sets are used across executions\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # build LSTM model\n",
    "    # 2 LSTM layers \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    model.add(LSTM(units=50))\n",
    "    # dense output layer\n",
    "    model.add(Dense(units=1))\n",
    "\n",
    "    # compile\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # train\n",
    "    model.fit(x_train, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "    # evaluate\n",
    "    test_loss = model.evaluate(x_test, y_test)\n",
    "\n",
    "    # define variable for test_loss output\n",
    "    test_loss_output = f'Test Loss: {test_loss}'\n",
    "\n",
    "    # predict\n",
    "    predictions = model.predict(x_test)\n",
    "\n",
    "    # unscale the data so that it is back in the original form\n",
    "    predictions = scaler.inverse_transform(np.concatenate((x_test[:, -1, 0:2], predictions.reshape(-1, 1)), axis=1))[:, 2]\n",
    "    \n",
    "    # evaluate\n",
    "    actual_close = scaler.inverse_transform(np.concatenate((x_test[:, -1, 0:2], y_test.reshape(-1, 1)), axis=1))[:, 2]\n",
    "  \n",
    "    mae = mean_absolute_error(actual_close, predictions)\n",
    "    mae_output = f'Mean Absolute Error: {mae}'\n",
    "    return predictions, test_loss_output, mae_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62bdcf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 3s 9ms/step - loss: 0.2173\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0918\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0484\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0519\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0501\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0360\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0313\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0313\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0307\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0277\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0261\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0273\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0316\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0306\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0261\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0255\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0254\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0248\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0245\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0242\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0240\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0242\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0245\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0248\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0245\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0238\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0232\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0229\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0225\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0223\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0221\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0218\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0214\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0215\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0218\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0215\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0206\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0210\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0208\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0199\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0202\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0201\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0196\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0192\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0196\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0192\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0187\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0186\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0186\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0184\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.0192\n",
      "1/1 [==============================] - 1s 580ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([108.01542726,  98.5412247 , 102.20982773, 100.99398736,\n",
       "         98.82535949, 110.3391464 ,  98.27381104, 100.08089034,\n",
       "         97.64291405, 110.71809557, 114.37922221, 109.67295321,\n",
       "        106.36720028, 110.38503832, 113.13555937, 109.40926233,\n",
       "        106.92204085, 109.15304677]),\n",
       " 'Test Loss: 0.019239556044340134',\n",
       " 'Mean Absolute Error: 3.6612329058305906')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(nike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8baea2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 3s 7ms/step - loss: 0.3050\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1631\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0782\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0610\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0737\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0596\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0474\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0476\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0487\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0466\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0428\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0422\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0417\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0414\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0404\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0397\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0398\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0396\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0393\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0385\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0381\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0377\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0374\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0371\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0369\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0367\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0364\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0359\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0357\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0358\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0351\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0347\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0345\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0342\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0342\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0337\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0332\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0330\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0329\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0330\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0327\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0324\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0320\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0317\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0315\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0312\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0316\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0311\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0307\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0306\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 0.0190\n",
      "1/1 [==============================] - 1s 738ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([100.23816096,  95.4026091 ,  94.34531086, 101.87500116,\n",
       "        100.05231546,  99.58781405, 102.49934253,  98.43743494,\n",
       "        103.43291968,  96.02916689, 105.89282643, 101.07954077,\n",
       "         95.03499691, 100.2683296 , 102.1882648 ,  99.96601979,\n",
       "         99.60846301, 100.51413095, 102.2259052 , 101.94899345,\n",
       "         96.41532084, 101.34241817]),\n",
       " 'Test Loss: 0.018969757482409477',\n",
       " 'Mean Absolute Error: 2.6421495361778913')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(starbucks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff2b40b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 3s 8ms/step - loss: 0.1341\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0641\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0553\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0356\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0317\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0275\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0273\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0263\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0258\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0252\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0254\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0252\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0248\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0248\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0242\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0246\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0243\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0239\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0246\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0239\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0237\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0235\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0234\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0234\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0235\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0230\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0230\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0228\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0228\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0225\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0226\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0235\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0227\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0225\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0226\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0219\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0217\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0219\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0218\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0212\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0212\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0213\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0210\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0207\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0208\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0207\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0209\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0206\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0202\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0210\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0143\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([132.72089959, 148.47239925, 147.35265885, 121.31633729,\n",
       "        127.37405059, 135.65514223, 114.92178903, 133.10141759,\n",
       "        155.36987382, 156.62607164, 125.84379527, 129.47000323,\n",
       "        121.00571473, 125.52150557, 157.13084725, 128.48497834,\n",
       "        160.02976199, 109.16155503, 145.38470538, 153.02582692,\n",
       "        160.73220885, 119.40234434, 118.9564242 , 120.65275154,\n",
       "        113.38125301, 132.81725659, 125.68519133]),\n",
       " 'Test Loss: 0.014349307864904404',\n",
       " 'Mean Absolute Error: 6.700150104850051')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ec5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
