{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deadd13a",
   "metadata": {},
   "source": [
    "## for runtime purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96481994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "a = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c046b2e",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154525ac",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43f7964f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laureneterno/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from functools import reduce\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52bbaca",
   "metadata": {},
   "source": [
    "## Save excel files from data cleaning stage into DataFrames and name the timestamp column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "361331f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nike = pd.read_excel('nike.xlsx')\n",
    "starbucks = pd.read_excel('starbucks.xlsx')\n",
    "target = pd.read_excel('target.xlsx')\n",
    "\n",
    "nike = nike.rename(columns = {'Unnamed: 0': 'timestamp'})\n",
    "starbucks = starbucks.rename(columns = {'Unnamed: 0': 'timestamp'})\n",
    "target = target.rename(columns = {'Unnamed: 0': 'timestamp'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f692e6",
   "metadata": {},
   "source": [
    "## Define getPolarity function that uses the TextBlob library to perform sentiment analysis on the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a852ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPolarity(text):\n",
    "   return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684263d4",
   "metadata": {},
   "source": [
    "## Define sentiment analysis function that cleans the string data and assigns each date a polarity score using the TextBlob library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5be963cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(df):\n",
    "    list = []\n",
    "    for x in df['comments']:\n",
    "    \n",
    "        # changes all of the characters to lowercase\n",
    "        x = str.lower(x)\n",
    "    \n",
    "        # removes all special characters\n",
    "        x = re.sub(r'[^a-zA-Z0-9\\s]+', '', x)\n",
    "    \n",
    "        # adds the modified column values to a list\n",
    "        list.append(x)\n",
    "\n",
    "        # adds the nike_list to a new dataframe\n",
    "        new_df = pd.DataFrame(list, columns =['comments'])\n",
    "\n",
    "    # adds the timestamps to the new dataframe\n",
    "    new_df = new_df.join(df['timestamp'])\n",
    "\n",
    "    # performs sentiment analysis on the comments from each day\n",
    "    new_df['polarity_score'] = new_df['comments'].apply(getPolarity)\n",
    "\n",
    "    # rearrange column order\n",
    "    new_df = new_df[['timestamp', 'polarity_score','comments']]\n",
    "\n",
    "    # set timestamp as index\n",
    "    new_df.set_index('timestamp')\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fac572",
   "metadata": {},
   "source": [
    "## Creates the new dataframe using the sentiment analysis function on each company's dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "941a2e2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nike = sentiment_analysis(nike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c155685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks = sentiment_analysis(starbucks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ec4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = sentiment_analysis(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35449831",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e861e93",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c9883fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 22:34:39.360256: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089d6714",
   "metadata": {},
   "source": [
    "## save the stock data into csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5875ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nike_stock = pd.read_csv('nike_stock.csv')\n",
    "starbucks_stock = pd.read_csv('starbucks_stock.csv')\n",
    "target_stock = pd.read_csv('target_stock.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6101101b",
   "metadata": {},
   "source": [
    "## combine the stock data and sentiment analysis data together. we chose the close price to be our output variable for the LSTM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6ebe7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_and_clean(stock, sa):\n",
    "    \n",
    "    # drop columns not needed from initial data retreival\n",
    "    stock = stock.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis = 1)\n",
    "    \n",
    "    # change columns to datetime type\n",
    "    sa['timestamp'] = pd.to_datetime(sa['timestamp'])\n",
    "    stock['Date'] = pd.to_datetime(stock['Date'])\n",
    "    \n",
    "    # perform an inner join to combine the dataframes by the dates available for both the sentiment analysis and the stock data\n",
    "    sa = sa.merge(stock, how = 'inner', left_on='timestamp', right_on = 'Date')\n",
    "    \n",
    "    # drop the date column as it is the same as the timestamp column (since the join was performed) and drop the comments column as the sentiment analysis was already completed\n",
    "    sa = sa.drop(['Date', 'comments'], axis = 1)\n",
    "    \n",
    "    # rename the Close column to close to match the lowercase in the other column names\n",
    "    sa = sa.rename(columns = {'Close': 'close'})\n",
    "    \n",
    "    # rename the timestamp column to date\n",
    "    sa = sa.rename(columns = {'timestamp':'date'})\n",
    "    \n",
    "    # Convert 'date' to numerical feature (number of days since the start)\n",
    "    sa['days_since_start'] = (sa['date'] - sa['date'].min()).dt.days\n",
    "        \n",
    "    #return the cleaned dataframe\n",
    "    return sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "341bb20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nike = combine_and_clean(nike_stock, nike)\n",
    "starbucks = combine_and_clean(starbucks_stock, starbucks)\n",
    "target = combine_and_clean(target_stock, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462f16d8",
   "metadata": {},
   "source": [
    "## Create a long short term memory model for each of the companies that uses the date (normalized as date since the earliest date) and polarity_score from sentiment analysis as input variables and the close price as the output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e969f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(df):\n",
    "    # feature selection\n",
    "    features = df[['days_since_start', 'polarity_score', 'close']].values\n",
    "    \n",
    "    # scale the values between 0 and 1 (this is optimal for LSTM)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled = scaler.fit_transform(features)\n",
    "\n",
    "    # Define nested function to create dataset with input features and target variable\n",
    "    def create_dataset(data, length):\n",
    "        # x represents the input features\n",
    "        # y represents the output variables\n",
    "        x, y = [], []\n",
    "        for i in range(len(data) - length):\n",
    "            a = data[i:(i + length), :]\n",
    "            x.append(a)\n",
    "            y.append(data[i + length, 2])  # 'close' is the third column\n",
    "        return np.array(x), np.array(y)\n",
    "\n",
    "    # determines the sequence length for each input\n",
    "    length = 10\n",
    "\n",
    "    # create dataset\n",
    "    x, y = create_dataset(scaled, length)\n",
    "\n",
    "    # split data into training and testing\n",
    "    # test size is 20% of data\n",
    "    # random_state = 42 means that the same training and testing sets are used across executions\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "    # build LSTM model\n",
    "    # 2 LSTM layers \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    model.add(LSTM(units=50))\n",
    "    # dense output layer\n",
    "    model.add(Dense(units=1))\n",
    "\n",
    "    # compile\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # train\n",
    "    model.fit(x_train, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "    # evaluate\n",
    "    test_loss = model.evaluate(x_test, y_test)\n",
    "\n",
    "    # define variable for test_loss output\n",
    "    test_loss_output = f'Test Loss: {test_loss}'\n",
    "\n",
    "    # predict\n",
    "    predictions = model.predict(x_test)\n",
    "\n",
    "    # unscale the data so that it is back in the original form\n",
    "    predictions = scaler.inverse_transform(np.concatenate((x_test[:, -1, 0:2], predictions.reshape(-1, 1)), axis=1))[:, 2]\n",
    "    \n",
    "    # evaluate\n",
    "    actual_close = scaler.inverse_transform(np.concatenate((x_test[:, -1, 0:2], y_test.reshape(-1, 1)), axis=1))[:, 2]\n",
    "  \n",
    "    mae = mean_absolute_error(actual_close, predictions)\n",
    "    mae_output = f'Mean Absolute Error: {mae}'\n",
    "    return predictions, test_loss_output, mae_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62bdcf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 3s 10ms/step - loss: 0.1992\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0776\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0461\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0679\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0529\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0379\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0370\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0373\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0356\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0317\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0281\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0281\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0278\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0251\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0236\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0253\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0245\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0226\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0226\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0236\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0222\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0216\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0216\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0213\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0213\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0210\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0209\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0207\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0206\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0206\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0200\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0202\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0207\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0204\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0196\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0197\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0198\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0195\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0190\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0186\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0188\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0191\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0191\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0183\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0181\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0180\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0178\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0179\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0176\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0169\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.0293\n",
      "1/1 [==============================] - 1s 541ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([109.48851782, 109.03080442, 108.54427431, 108.08426195,\n",
       "        107.66473546, 107.63872813, 107.26443003, 107.01468175,\n",
       "        106.92678231, 107.06728977, 107.53760384, 108.6310498 ,\n",
       "        109.62676993, 110.72901827, 111.79984684, 113.22537815,\n",
       "        112.93016116, 111.95745611]),\n",
       " 'Test Loss: 0.02926524542272091',\n",
       " 'Mean Absolute Error: 4.644756034481897')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(nike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8baea2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 9ms/step - loss: 0.2794\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1308\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0548\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0557\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0688\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0515\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0425\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0428\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0447\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0432\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0401\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0381\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0382\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0382\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0373\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0363\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0360\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0359\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0356\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0349\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0345\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0342\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0339\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0336\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0333\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0326\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0323\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0320\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0314\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0314\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0309\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0305\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0299\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0299\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0295\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0288\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0285\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0279\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0275\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0273\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0270\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0270\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0259\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0259\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0252\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0247\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0251\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0242\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0243\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0237\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.0438\n",
      "1/1 [==============================] - 1s 722ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([102.08050462, 101.93891967, 101.76612167, 101.79896583,\n",
       "        101.58724029, 102.19354372, 102.71302512, 103.0236493 ,\n",
       "        103.64531514, 103.31294003, 102.45362562, 101.50394401,\n",
       "        100.48122299,  99.77033838,  99.02616161,  99.39032537,\n",
       "         99.61892862, 100.68793105, 102.90757821, 103.91374955,\n",
       "        103.26707749, 102.76861607]),\n",
       " 'Test Loss: 0.04375164210796356',\n",
       " 'Mean Absolute Error: 4.073746967501189')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(starbucks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff2b40b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 2s 10ms/step - loss: 0.2529\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1086\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0692\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0514\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0313\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0311\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0316\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0296\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0277\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0262\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0260\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0264\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0257\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0254\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0259\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0261\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0255\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0248\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0249\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0242\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0243\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0245\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0244\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0242\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0238\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0234\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0235\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0230\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0230\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0226\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0227\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0230\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0220\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0222\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0224\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0215\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0217\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0214\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0214\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0214\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0210\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0209\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0210\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0222\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0215\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0211\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0207\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0207\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0206\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0219\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 0.0153\n",
      "1/1 [==============================] - 1s 518ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([133.08718162, 132.74066199, 130.88496608, 131.05109824,\n",
       "        131.42109176, 131.54368264, 131.35630176, 130.21453942,\n",
       "        130.28784351, 130.42551232, 131.00896165, 130.3600436 ,\n",
       "        130.93389633, 130.45707288, 129.52146365, 130.83743408,\n",
       "        130.51574579, 129.63202655, 129.1026258 , 129.26300171,\n",
       "        129.59862743, 130.95766877, 130.62926199, 130.94545822,\n",
       "        132.98812262, 135.43499155, 139.92760061]),\n",
       " 'Test Loss: 0.015270217321813107',\n",
       " 'Mean Absolute Error: 5.4967920476471575')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74667c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.282397031784058"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runtime in seconds\n",
    "b= time.time()\n",
    "b - a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
